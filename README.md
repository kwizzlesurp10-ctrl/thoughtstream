# ThoughtStream: Intelligent Context-Aware Note-Taking Daemon

ğŸš€ **Intelligent context-aware note-taking daemon for developers with local LLM integration (Ollama/Llama 3.2)**

Captures your dev/research workflow ethically: terminal commands, IDE files, browser tabs, voluntary clipboard/hotkeys. Segments sessions via git/pwd. Powers natural-language recall with local Ollama for zero-cloud embeddings & queries. Exports to Obsidian, suggests git commits. <15MB RAM, E2E privacy.

## ğŸŒŸ Key Features

### Smart Capture
- **Terminal Integration**: PTY proxy captures all commands and output
- **IDE Monitoring**: VSCode/JetBrains file tracking
- **Browser Activity**: Tab titles via xdotool
- **Voluntary Clipboard**: Manual capture on demand
- **Global Hotkeys**: Super+Shift+N for quick notes

### Local LLM Integration
- **Embeddings**: `nomic-embed-text` via Ollama (384-dim vectors)
- **Queries**: `llama3.2:3b` for semantic reranking & generation
- **Hybrid Search**: FTS5 + cosine similarity via `sqlite-vss`
- **Zero-Cloud**: All processing happens locally

### Intelligence
- **Session Detection**: Automatic context switching via git/pwd
- **Natural Language Recall**: Ask "what was I debugging with Redis last Thursday?"
- **Git Commit Suggestions**: Auto-generated from recent activity
- **Timeline Visualization**: Activity heatmap and context flow

### Privacy First
- **No Background Keylogging**: Opt-in capture only
- **Blacklist Support**: Exclude sensitive apps/directories
- **Encryption**: Age/GPG encryption at rest
- **Retention Policies**: Configurable data lifecycle
- **Audit Trail**: Full transparency of captured data

## ğŸ“¦ Installation

### Prerequisites

```bash
# Ubuntu 22.04+, Python 3.10+
sudo apt install git curl xdotool evdev

# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull required models
ollama pull nomic-embed-text llama3.2:3b
```

> **Windows note:** `sqlite-vss` does not currently ship prebuilt wheels for
> Windows. Pick one of the options below before continuing with the install:
>
> 1. **Use WSL** â€“ recommended if you already have Windows Subsystem for Linux
>    enabled. Run the Linux prerequisites above inside WSL and install normally.
> 2. **Build `sqlite-vss` from source on Windows** â€“ requires the Rust toolchain
>    and Microsoftâ€™s C++ Build Tools.

### Building `sqlite-vss` on Windows (Manual)

1. Install [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/) with the *C++ build tools* workload.
2. Install the Rust toolchain via [rustup](https://rustup.rs/).
3. Install `maturin` into your virtual environment: `pip install maturin`.
4. Clone the upstream project and build the wheel:

   ```powershell
   git clone https://github.com/asg017/sqlite-vss.git
   cd sqlite-vss\python
   maturin build --release --strip
   ```

   The wheel will be written to `python\target\wheels\`.

5. Install the resulting wheel into your ThoughtStream environment:

   ```powershell
   pip install .\target\wheels\sqlite_vss-*.whl
   ```

6. Return to the ThoughtStream repo and continue with `pip install -e .`.

If you prefer to run without vector search for now, comment out or remove
`sqlite-vss` from `pyproject.toml` and set `llm.hybrid_search` to `false` in
your config; the daemon will operate without the hybrid similarity index.

### One-Click Install

```bash
git clone https://github.com/kwizzlesurp10-ctrl/thoughtstream.git
cd thoughtstream
./scripts/install.sh
```

The installer will:
1. Create virtual environment
2. Install all dependencies
3. Setup systemd user service
4. Create config directory
5. Start the daemon

### Manual Installation

```bash
python3 -m venv venv
source venv/bin/activate
pip install -e .

# Copy config
mkdir -p ~/.config/thoughtstream
cp config.yaml.example ~/.config/thoughtstream/config.yaml

# Start daemon
thoughtstream daemon
```

## ğŸ¯ Usage

### CLI Commands

```bash
# Start daemon (auto-starts via systemd)
systemctl --user start thoughtstream

# Natural language recall
thoughtstream recall "yesterday's postgres debug"
thoughtstream recall "API integration notes from last week"

# Visual timeline
thoughtstream timeline 24  # Last 24 hours

# Export to Obsidian/Notion
thoughtstream export obsidian

# View statistics
thoughtstream stats
```

### Quick Notes Hotkey

Press `Super+Shift+N` anywhere to capture clipboard content as a quick note.

### Configuration

Edit `~/.config/thoughtstream/config.yaml`:

```yaml
database:
  path: ~/.local/share/thoughtstream/thoughtstream.db
  retention_days: 30

llm:
  provider: ollama
  embedding_model: nomic-embed-text
  query_model: llama3.2:3b
  host: http://localhost:11434
  hybrid_search: true

capture:
  blacklist_apps: [firefox:password, chrome:banking]
  blacklist_dirs: [/etc, /var]
  poll_interval: 5

privacy:
  encrypt: false
  retention_policy: keep_all_except_blacklist

export:
  obsidian_vault: ~/Obsidian/Notes
```

## ğŸ—ï¸ Architecture

```
thoughtstream/
â”œâ”€â”€ daemon.py              # Async core daemon
â”œâ”€â”€ db.py                  # SQLite + VSS + Ollama
â”œâ”€â”€ intelligence.py        # Session logic + NL search
â”œâ”€â”€ config.py              # YAML configuration
â”œâ”€â”€ crypto.py              # Age encryption
â””â”€â”€ capture/
    â”œâ”€â”€ terminal.py        # PTY proxy for commands
    â”œâ”€â”€ clipboard.py       # Pyperclip hook
    â”œâ”€â”€ hotkeys.py         # Pynput global hotkeys
    â”œâ”€â”€ vscode.py          # IDE file polling
    â””â”€â”€ browser.py         # xdotool tab titles
```

## ğŸ”§ Technical Details

### Dependencies
- **Python 3.10+**: Async/await support
- **SQLite + sqlite-vss**: Vector search extension
- **Ollama**: Local LLM inference
- **pynput**: Global hotkey capture
- **pyperclip**: Clipboard monitoring
- **Rich**: Terminal UI
- **Typer**: CLI framework

### Performance
- **Idle RAM**: <15MB
- **Query Time**: <50ms (FTS5 + vector hybrid)
- **Embedding Speed**: ~100 tokens/sec on CPU
- **Storage**: ~1MB per 1000 entries

## ğŸ­ Use Cases

- **ADHD Developers**: Context switching between multiple projects
- **Researchers**: Processing large amounts of information
- **Technical Writers**: Documenting workflows
- **Students**: Note-taking across multiple sources
- **Anyone**: Scattered thinking patterns and memory augmentation

## ğŸ›¡ï¸ Privacy & Ethics

ThoughtStream is designed with privacy as the foundation:

âœ… **Opt-in Only**: No background keylogging of GUI apps
âœ… **Local Processing**: All LLM inference happens on your machine
âœ… **Transparent**: Full audit trail of what's captured
âœ… **Configurable**: Blacklist any app or directory
âœ… **Encrypted**: Optional end-to-end encryption
âœ… **Deletable**: Full control over data retention

### What ThoughtStream DOES NOT Do
- âŒ Global keystroke logging
- âŒ Password manager monitoring
- âŒ Banking app capture
- âŒ Cloud data transmission
- âŒ Hidden background processes

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- **Ollama**: Local LLM inference engine
- **sqlite-vss**: Vector similarity search
- **Grok AI**: Implementation assistance
- **xAI**: Project inspiration

## ğŸ“š Documentation

For detailed documentation, see:
- [Installation Guide](docs/installation.md)
- [Configuration Reference](docs/configuration.md)
- [API Documentation](docs/api.md)
- [Troubleshooting](docs/troubleshooting.md)

## ğŸš€ Roadmap

- [ ] Web UI dashboard
- [ ] Mobile companion app
- [ ] Obsidian plugin
- [ ] VSCode extension
- [ ] Git integration improvements
- [ ] Multi-language support
- [ ] Advanced analytics

---

**Built with Machiavellian precision: Capture chaos, reclaim genius. No cloud overlords.**

*ThoughtStream - Your context-aware memory augmentation system*
